{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7484294,"sourceType":"datasetVersion","datasetId":4356957},{"sourceId":7714748,"sourceType":"datasetVersion","datasetId":4505447},{"sourceId":7738426,"sourceType":"datasetVersion","datasetId":4522789},{"sourceId":7741634,"sourceType":"datasetVersion","datasetId":4524977}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:11:37.613402Z","iopub.execute_input":"2024-02-29T05:11:37.613811Z","iopub.status.idle":"2024-02-29T05:11:37.618565Z","shell.execute_reply.started":"2024-02-29T05:11:37.613774Z","shell.execute_reply":"2024-02-29T05:11:37.617488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport ast\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:11:39.302903Z","iopub.execute_input":"2024-02-29T05:11:39.303279Z","iopub.status.idle":"2024-02-29T05:11:39.309799Z","shell.execute_reply.started":"2024-02-29T05:11:39.303248Z","shell.execute_reply":"2024-02-29T05:11:39.308845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/bmi-labels/labels_utf8.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:11:45.721420Z","iopub.execute_input":"2024-02-29T05:11:45.722289Z","iopub.status.idle":"2024-02-29T05:11:45.961820Z","shell.execute_reply.started":"2024-02-29T05:11:45.722254Z","shell.execute_reply":"2024-02-29T05:11:45.960989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:11:49.919884Z","iopub.execute_input":"2024-02-29T05:11:49.920639Z","iopub.status.idle":"2024-02-29T05:11:49.934602Z","shell.execute_reply.started":"2024-02-29T05:11:49.920607Z","shell.execute_reply":"2024-02-29T05:11:49.933671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop([\"Hair\", \"Eyes\", \"Race\", \"Sex Offender\", \"Offense\"], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:11:55.523316Z","iopub.execute_input":"2024-02-29T05:11:55.524131Z","iopub.status.idle":"2024-02-29T05:11:55.531852Z","shell.execute_reply.started":"2024-02-29T05:11:55.524096Z","shell.execute_reply":"2024-02-29T05:11:55.530861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:11:57.393366Z","iopub.execute_input":"2024-02-29T05:11:57.393767Z","iopub.status.idle":"2024-02-29T05:11:57.404050Z","shell.execute_reply.started":"2024-02-29T05:11:57.393735Z","shell.execute_reply":"2024-02-29T05:11:57.403173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:12:00.019337Z","iopub.execute_input":"2024-02-29T05:12:00.020245Z","iopub.status.idle":"2024-02-29T05:12:00.025777Z","shell.execute_reply.started":"2024-02-29T05:12:00.020211Z","shell.execute_reply":"2024-02-29T05:12:00.024750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:12:02.765198Z","iopub.execute_input":"2024-02-29T05:12:02.765573Z","iopub.status.idle":"2024-02-29T05:12:02.796670Z","shell.execute_reply.started":"2024-02-29T05:12:02.765538Z","shell.execute_reply":"2024-02-29T05:12:02.795710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:12:04.071861Z","iopub.execute_input":"2024-02-29T05:12:04.072222Z","iopub.status.idle":"2024-02-29T05:12:04.076490Z","shell.execute_reply.started":"2024-02-29T05:12:04.072193Z","shell.execute_reply":"2024-02-29T05:12:04.075481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install dlib","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:12:56.202709Z","iopub.execute_input":"2024-02-29T05:12:56.203083Z","iopub.status.idle":"2024-02-29T05:13:07.985094Z","shell.execute_reply.started":"2024-02-29T05:12:56.203053Z","shell.execute_reply":"2024-02-29T05:13:07.983920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import dlib\nimport os\nimport numpy as np\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:13:14.310291Z","iopub.execute_input":"2024-02-29T05:13:14.310694Z","iopub.status.idle":"2024-02-29T05:13:14.737701Z","shell.execute_reply.started":"2024-02-29T05:13:14.310660Z","shell.execute_reply":"2024-02-29T05:13:14.736735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize dlib's face detector (HOG-based)\ndetector = dlib.get_frontal_face_detector()\n\n# Path to the directory containing images to process\npath = \"/kaggle/input/sideimage/Dataset/front/front\"","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:18:05.348037Z","iopub.execute_input":"2024-02-29T05:18:05.348417Z","iopub.status.idle":"2024-02-29T05:18:05.805391Z","shell.execute_reply.started":"2024-02-29T05:18:05.348391Z","shell.execute_reply":"2024-02-29T05:18:05.804408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arrays to store labels and cropped images\nX = []\nY = []","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:18:11.025288Z","iopub.execute_input":"2024-02-29T05:18:11.025979Z","iopub.status.idle":"2024-02-29T05:18:11.030208Z","shell.execute_reply.started":"2024-02-29T05:18:11.025939Z","shell.execute_reply":"2024-02-29T05:18:11.029272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate through each file in the directory\nfor filename in os.listdir(path):\n    if filename.endswith('.jpg'):\n        # Construct absolute file path\n        file_path = os.path.join(path, filename)\n        \n        # Load the image\n        image = dlib.load_rgb_image(file_path)\n        \n        # Detect faces in the image\n        detected_faces = detector(image, 1)\n        \n        # If at least one face is detected\n        if len(detected_faces) > 0:\n            # For each face detected\n            for index, face_rect in enumerate(detected_faces):\n                # Get the bounding box of the face\n                x, y, w, h = (face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height())\n\n                # Crop the face (convert dlib's image to a PIL Image first)\n                face_image = Image.fromarray(image).crop((x, y, x+w, y+h))\n                \n                # Convert the cropped face image to a NumPy array and append to X\n                face_array = np.array(face_image)\n                X.append(face_array)\n                \n                # Store the label in array Y (strip the .jpg extension)\n                label = filename.split('.')[0]\n                Y.append(label)\n        else:\n            print(f\"No face detected in {filename}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:18:43.256844Z","iopub.execute_input":"2024-02-29T05:18:43.257228Z","iopub.status.idle":"2024-02-29T07:36:42.498161Z","shell.execute_reply.started":"2024-02-29T05:18:43.257197Z","shell.execute_reply":"2024-02-29T07:36:42.497085Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X))\nprint(len(Y))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:38:28.352957Z","iopub.execute_input":"2024-02-29T07:38:28.353828Z","iopub.status.idle":"2024-02-29T07:38:28.358869Z","shell.execute_reply.started":"2024-02-29T07:38:28.353796Z","shell.execute_reply":"2024-02-29T07:38:28.357861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:42:16.191384Z","iopub.execute_input":"2024-02-29T07:42:16.192243Z","iopub.status.idle":"2024-02-29T07:42:16.196138Z","shell.execute_reply.started":"2024-02-29T07:42:16.192207Z","shell.execute_reply":"2024-02-29T07:42:16.195174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install facenet-pytorch","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:44:58.747386Z","iopub.execute_input":"2024-02-29T07:44:58.748322Z","iopub.status.idle":"2024-02-29T07:45:11.081261Z","shell.execute_reply.started":"2024-02-29T07:44:58.748285Z","shell.execute_reply":"2024-02-29T07:45:11.080161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom facenet_pytorch import InceptionResnetV1\nimport torchvision.transforms.functional as F\nimport torchvision.transforms as transforms\nimport numpy as np\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:58:04.036342Z","iopub.execute_input":"2024-02-29T07:58:04.037468Z","iopub.status.idle":"2024-02-29T07:58:04.041812Z","shell.execute_reply.started":"2024-02-29T07:58:04.037433Z","shell.execute_reply":"2024-02-29T07:58:04.040930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torchvision","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:51:20.249359Z","iopub.execute_input":"2024-02-29T07:51:20.250185Z","iopub.status.idle":"2024-02-29T07:51:32.094245Z","shell.execute_reply.started":"2024-02-29T07:51:20.250151Z","shell.execute_reply":"2024-02-29T07:51:32.093041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet = InceptionResnetV1(pretrained='vggface2').eval().to('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:46:28.365962Z","iopub.execute_input":"2024-02-29T07:46:28.366790Z","iopub.status.idle":"2024-02-29T07:46:30.906460Z","shell.execute_reply.started":"2024-02-29T07:46:28.366745Z","shell.execute_reply":"2024-02-29T07:46:30.905443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_face_embeddings(batch):\n    # Define the transformation pipeline\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),  # Resize the image\n        transforms.ToTensor(),  # Convert the image to a tensor\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the tensor\n    ])\n\n    # Convert numpy arrays to PIL Images if necessary and apply transformations\n    transformed_batch = []\n    for img in batch:\n        if isinstance(img, np.ndarray):\n            img = Image.fromarray(img)\n        transformed_img = transform(img)\n        transformed_batch.append(transformed_img)\n\n    # Stack the transformed images into a batch\n    batch_tensors = torch.stack(transformed_batch).to('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Compute embeddings\n    with torch.no_grad():\n        embeddings = resnet(batch_tensors).cpu().numpy()\n    \n    return embeddings\n","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:34:42.797111Z","iopub.execute_input":"2024-02-29T08:34:42.797558Z","iopub.status.idle":"2024-02-29T08:34:42.805529Z","shell.execute_reply.started":"2024-02-29T08:34:42.797502Z","shell.execute_reply":"2024-02-29T08:34:42.804563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"directory = \"/kaggle/input/frontcrop/frontcropped\"","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:35:03.904557Z","iopub.execute_input":"2024-03-01T17:35:03.905245Z","iopub.status.idle":"2024-03-01T17:35:03.909267Z","shell.execute_reply.started":"2024-03-01T17:35:03.905213Z","shell.execute_reply":"2024-03-01T17:35:03.908283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Not using for now\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T16:45:18.583186Z","iopub.execute_input":"2024-03-01T16:45:18.583503Z","iopub.status.idle":"2024-03-01T16:45:30.222541Z","shell.execute_reply.started":"2024-03-01T16:45:18.583479Z","shell.execute_reply":"2024-03-01T16:45:30.221727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Model\n\n# Load the MobileNet model, excluding the top (fully connected) layers\nbase_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the layers of the base model to prevent them from being updated during the first training phase\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n\n# Add a fully-connected layer with 256 units and a relu activation\nx = Dense(256, activation='relu')(x)\n\n# Create the model that will output the 256-dimensional embeddings\nmodelu = Model(inputs=base_model.input, outputs=x)\n\nmodelu.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:33:21.623408Z","iopub.execute_input":"2024-03-01T17:33:21.623989Z","iopub.status.idle":"2024-03-01T17:33:36.418004Z","shell.execute_reply.started":"2024-03-01T17:33:21.623955Z","shell.execute_reply":"2024-03-01T17:33:36.417121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to load images in batches\ndef load_images_in_batches(directory, batch_size=1000):\n    filenames = os.listdir(directory)\n    for i in range(0, len(filenames), batch_size):\n        batch_files = filenames[i:i+batch_size]\n        batch_images = []\n        for file in batch_files:\n            img_path = os.path.join(directory, file)\n            img = image.load_img(img_path, target_size=(224, 224))\n            img = image.img_to_array(img)\n            img = np.expand_dims(img, axis=0)\n            img = preprocess_input(img)\n            batch_images.append(img)\n        yield np.vstack(batch_images), batch_files","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:34:03.221555Z","iopub.execute_input":"2024-03-01T17:34:03.222370Z","iopub.status.idle":"2024-03-01T17:34:03.228819Z","shell.execute_reply.started":"2024-03-01T17:34:03.222339Z","shell.execute_reply":"2024-03-01T17:34:03.227814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare to save embeddings\nembeddings = []\nlabels = []","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:34:06.444308Z","iopub.execute_input":"2024-03-01T17:34:06.444648Z","iopub.status.idle":"2024-03-01T17:34:06.449070Z","shell.execute_reply.started":"2024-03-01T17:34:06.444621Z","shell.execute_reply":"2024-03-01T17:34:06.448019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:36:05.929960Z","iopub.execute_input":"2024-03-01T17:36:05.930329Z","iopub.status.idle":"2024-03-01T17:36:05.936469Z","shell.execute_reply.started":"2024-03-01T17:36:05.930298Z","shell.execute_reply":"2024-03-01T17:36:05.935459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Process images in batches\nfor images_batch, filenames in load_images_in_batches(directory):\n    # Generate embeddings\n    batch_embeddings = modelu.predict(images_batch)\n    embeddings.extend(batch_embeddings)\n    labels.extend([filename.split('.')[0] for filename in filenames])","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:36:10.397916Z","iopub.execute_input":"2024-03-01T17:36:10.398730Z","iopub.status.idle":"2024-03-01T17:46:50.112798Z","shell.execute_reply.started":"2024-03-01T17:36:10.398688Z","shell.execute_reply":"2024-03-01T17:46:50.111862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(embeddings))\nprint(len(labels))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:46:50.114926Z","iopub.execute_input":"2024-03-01T17:46:50.115296Z","iopub.status.idle":"2024-03-01T17:46:50.120603Z","shell.execute_reply.started":"2024-03-01T17:46:50.115262Z","shell.execute_reply":"2024-03-01T17:46:50.119685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings[3]","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:46:50.121727Z","iopub.execute_input":"2024-03-01T17:46:50.121977Z","iopub.status.idle":"2024-03-01T17:46:50.135485Z","shell.execute_reply.started":"2024-03-01T17:46:50.121955Z","shell.execute_reply":"2024-03-01T17:46:50.134534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_file_path = '/kaggle/working/embeddings.csv'","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:46:50.137781Z","iopub.execute_input":"2024-03-01T17:46:50.138098Z","iopub.status.idle":"2024-03-01T17:46:50.143896Z","shell.execute_reply.started":"2024-03-01T17:46:50.138071Z","shell.execute_reply":"2024-03-01T17:46:50.142889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert embeddings and labels into a DataFrame\ndf = pd.DataFrame(embeddings)\ndf['label'] = labels","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:46:50.145104Z","iopub.execute_input":"2024-03-01T17:46:50.145456Z","iopub.status.idle":"2024-03-01T17:47:01.513362Z","shell.execute_reply.started":"2024-03-01T17:46:50.145422Z","shell.execute_reply":"2024-03-01T17:47:01.512537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(csv_file_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:47:18.166957Z","iopub.execute_input":"2024-03-01T17:47:18.167314Z","iopub.status.idle":"2024-03-01T17:47:34.690089Z","shell.execute_reply.started":"2024-03-01T17:47:18.167281Z","shell.execute_reply":"2024-03-01T17:47:34.688966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:50:29.524188Z","iopub.execute_input":"2024-03-02T05:50:29.525232Z","iopub.status.idle":"2024-03-02T05:50:30.015739Z","shell.execute_reply.started":"2024-03-02T05:50:29.525175Z","shell.execute_reply":"2024-03-02T05:50:30.014500Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pit = pd.read_csv(\"/kaggle/input/frontembeddings-csv/embeddings.csv\")\npot = pd.read_csv(\"/kaggle/input/bmi-labels/labels_utf8.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:50:55.853044Z","iopub.execute_input":"2024-03-02T05:50:55.853637Z","iopub.status.idle":"2024-03-02T05:51:00.432129Z","shell.execute_reply.started":"2024-03-02T05:50:55.853593Z","shell.execute_reply":"2024-03-02T05:51:00.430684Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"pit.head(19)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:51:10.083731Z","iopub.execute_input":"2024-03-02T05:51:10.084133Z","iopub.status.idle":"2024-03-02T05:51:10.153265Z","shell.execute_reply.started":"2024-03-02T05:51:10.084102Z","shell.execute_reply":"2024-03-02T05:51:10.151792Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     label         0         1         2         3         4         5  \\\n0   M11813  0.111665  0.000000  0.000000  0.087155  0.000000  0.283555   \n1   M53326  0.000000  0.000000  0.000000  0.267790  0.000000  0.466448   \n2   Y22950  1.067019  0.000000  0.000000  0.354018  0.000000  0.774819   \n3   S09796  0.000000  0.000000  0.000000  0.000000  0.000000  1.491947   \n4   Y29851  0.000000  0.000000  0.000000  0.000000  0.000000  1.106095   \n5   Y13293  0.000000  0.000000  0.000000  0.138999  0.613604  1.378825   \n6   M11887  0.000000  0.000000  0.000000  0.000000  0.000000  0.310248   \n7   R59503  0.698034  0.000000  0.000000  0.000000  0.000000  0.359855   \n8   B58525  0.000000  0.000000  0.000000  0.000000  0.236257  0.000000   \n9   N71687  0.000000  0.000000  0.000000  0.000000  0.341415  1.964891   \n10  B50020  0.434556  0.039318  0.072553  0.196831  0.023275  0.642230   \n11  Y27766  0.225217  0.861199  0.000000  0.000000  0.000000  0.469101   \n12  B71690  0.000000  0.000000  0.000000  0.000000  0.000000  0.949785   \n13  M24399  0.060530  0.000000  0.000000  0.135637  0.249987  1.077966   \n14  Y27450  0.000000  0.000000  0.000000  0.000000  0.000000  0.925059   \n15  R53938  0.288067  0.000000  0.000000  0.000000  0.040030  1.467808   \n16  M54200  0.104958  0.000000  0.000000  0.000000  0.187106  1.199856   \n17  M42020  0.000000  0.000000  0.000000  0.280975  0.000000  0.862255   \n18  B53764  0.000000  0.000000  0.000000  0.000000  0.454560  1.099458   \n\n           6         7    8  ...       246       247       248       249  \\\n0   0.000000  0.000000  0.0  ...  0.000000  0.000000  0.945229  0.000000   \n1   0.000000  0.183102  0.0  ...  0.501978  0.000000  2.252731  0.000000   \n2   0.000000  0.000000  0.0  ...  0.000000  0.000000  0.651599  0.000000   \n3   0.000000  0.575940  0.0  ...  0.000000  0.000000  0.378559  0.000000   \n4   0.000000  0.676816  0.0  ...  0.608241  0.000000  0.362727  0.580366   \n5   0.000000  1.304752  0.0  ...  0.000000  0.000000  0.000000  0.000000   \n6   0.000000  0.000000  0.0  ...  0.000000  0.000000  0.000000  0.000000   \n7   0.000000  0.164804  0.0  ...  1.012527  0.482344  0.170199  0.000000   \n8   0.000000  0.133390  0.0  ...  0.000000  0.000000  0.000000  0.000000   \n9   0.000000  0.000000  0.0  ...  0.000000  0.000000  0.000000  0.000000   \n10  0.000000  0.000000  0.0  ...  0.726662  0.000000  0.895159  0.000000   \n11  0.000000  0.337660  0.0  ...  0.998242  0.000000  0.078536  0.172733   \n12  0.000000  0.000000  0.0  ...  0.000000  0.000000  1.700187  0.000000   \n13  0.000000  0.013928  0.0  ...  0.000000  0.000000  0.000000  0.000000   \n14  0.000000  0.515269  0.0  ...  0.000000  0.000000  0.000000  0.000000   \n15  0.000000  0.483660  0.0  ...  0.000000  0.000000  0.000000  0.000000   \n16  0.285849  0.000000  0.0  ...  0.319139  0.535698  1.611846  0.000000   \n17  0.000000  0.266741  0.0  ...  0.040243  0.000000  0.794889  0.000000   \n18  0.000000  0.000000  0.0  ...  0.000000  0.000000  0.216294  0.000000   \n\n         250       251  252       253       254       255  \n0   1.393281  2.282689  0.0  0.973255  0.000000  0.000000  \n1   1.852022  3.060644  0.0  0.076265  0.000000  0.000000  \n2   1.578468  1.465300  0.0  0.529442  0.000000  0.417858  \n3   1.444114  2.393884  0.0  1.355780  0.000000  0.000000  \n4   0.235768  1.732123  0.0  0.844815  0.000000  0.000000  \n5   0.000000  2.650397  0.0  0.383372  0.000000  0.153848  \n6   2.543493  2.195034  0.0  1.370752  0.000000  0.654439  \n7   0.085531  3.104510  0.0  1.542924  0.000000  0.000000  \n8   1.346857  3.139775  0.0  0.596800  0.000000  0.431893  \n9   1.692624  2.699712  0.0  0.622131  0.000000  0.345724  \n10  1.136816  2.729304  0.0  2.591678  0.000000  0.000000  \n11  0.046671  1.546477  0.0  0.803954  0.272863  0.125175  \n12  1.580764  2.946902  0.0  0.507580  0.114415  0.000000  \n13  1.204849  2.341309  0.0  1.714279  0.000000  0.000000  \n14  2.199632  2.293536  0.0  1.348804  0.259046  0.000000  \n15  1.354492  1.799956  0.0  0.117215  0.000000  0.843189  \n16  1.367887  3.186100  0.0  2.389843  0.000000  0.000000  \n17  1.341829  2.483617  0.0  1.689135  0.000000  0.022693  \n18  0.003337  2.232541  0.0  0.268575  0.000000  0.000000  \n\n[19 rows x 257 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>246</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n      <th>250</th>\n      <th>251</th>\n      <th>252</th>\n      <th>253</th>\n      <th>254</th>\n      <th>255</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M11813</td>\n      <td>0.111665</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.087155</td>\n      <td>0.000000</td>\n      <td>0.283555</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.945229</td>\n      <td>0.000000</td>\n      <td>1.393281</td>\n      <td>2.282689</td>\n      <td>0.0</td>\n      <td>0.973255</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M53326</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.267790</td>\n      <td>0.000000</td>\n      <td>0.466448</td>\n      <td>0.000000</td>\n      <td>0.183102</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.501978</td>\n      <td>0.000000</td>\n      <td>2.252731</td>\n      <td>0.000000</td>\n      <td>1.852022</td>\n      <td>3.060644</td>\n      <td>0.0</td>\n      <td>0.076265</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Y22950</td>\n      <td>1.067019</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.354018</td>\n      <td>0.000000</td>\n      <td>0.774819</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.651599</td>\n      <td>0.000000</td>\n      <td>1.578468</td>\n      <td>1.465300</td>\n      <td>0.0</td>\n      <td>0.529442</td>\n      <td>0.000000</td>\n      <td>0.417858</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>S09796</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.491947</td>\n      <td>0.000000</td>\n      <td>0.575940</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.378559</td>\n      <td>0.000000</td>\n      <td>1.444114</td>\n      <td>2.393884</td>\n      <td>0.0</td>\n      <td>1.355780</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Y29851</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.106095</td>\n      <td>0.000000</td>\n      <td>0.676816</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.608241</td>\n      <td>0.000000</td>\n      <td>0.362727</td>\n      <td>0.580366</td>\n      <td>0.235768</td>\n      <td>1.732123</td>\n      <td>0.0</td>\n      <td>0.844815</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Y13293</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.138999</td>\n      <td>0.613604</td>\n      <td>1.378825</td>\n      <td>0.000000</td>\n      <td>1.304752</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.650397</td>\n      <td>0.0</td>\n      <td>0.383372</td>\n      <td>0.000000</td>\n      <td>0.153848</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>M11887</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.310248</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.543493</td>\n      <td>2.195034</td>\n      <td>0.0</td>\n      <td>1.370752</td>\n      <td>0.000000</td>\n      <td>0.654439</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>R59503</td>\n      <td>0.698034</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.359855</td>\n      <td>0.000000</td>\n      <td>0.164804</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.012527</td>\n      <td>0.482344</td>\n      <td>0.170199</td>\n      <td>0.000000</td>\n      <td>0.085531</td>\n      <td>3.104510</td>\n      <td>0.0</td>\n      <td>1.542924</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>B58525</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.236257</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.133390</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.346857</td>\n      <td>3.139775</td>\n      <td>0.0</td>\n      <td>0.596800</td>\n      <td>0.000000</td>\n      <td>0.431893</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>N71687</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.341415</td>\n      <td>1.964891</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.692624</td>\n      <td>2.699712</td>\n      <td>0.0</td>\n      <td>0.622131</td>\n      <td>0.000000</td>\n      <td>0.345724</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>B50020</td>\n      <td>0.434556</td>\n      <td>0.039318</td>\n      <td>0.072553</td>\n      <td>0.196831</td>\n      <td>0.023275</td>\n      <td>0.642230</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.726662</td>\n      <td>0.000000</td>\n      <td>0.895159</td>\n      <td>0.000000</td>\n      <td>1.136816</td>\n      <td>2.729304</td>\n      <td>0.0</td>\n      <td>2.591678</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Y27766</td>\n      <td>0.225217</td>\n      <td>0.861199</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.469101</td>\n      <td>0.000000</td>\n      <td>0.337660</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.998242</td>\n      <td>0.000000</td>\n      <td>0.078536</td>\n      <td>0.172733</td>\n      <td>0.046671</td>\n      <td>1.546477</td>\n      <td>0.0</td>\n      <td>0.803954</td>\n      <td>0.272863</td>\n      <td>0.125175</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>B71690</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.949785</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.700187</td>\n      <td>0.000000</td>\n      <td>1.580764</td>\n      <td>2.946902</td>\n      <td>0.0</td>\n      <td>0.507580</td>\n      <td>0.114415</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>M24399</td>\n      <td>0.060530</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.135637</td>\n      <td>0.249987</td>\n      <td>1.077966</td>\n      <td>0.000000</td>\n      <td>0.013928</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.204849</td>\n      <td>2.341309</td>\n      <td>0.0</td>\n      <td>1.714279</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Y27450</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.925059</td>\n      <td>0.000000</td>\n      <td>0.515269</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.199632</td>\n      <td>2.293536</td>\n      <td>0.0</td>\n      <td>1.348804</td>\n      <td>0.259046</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>R53938</td>\n      <td>0.288067</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.040030</td>\n      <td>1.467808</td>\n      <td>0.000000</td>\n      <td>0.483660</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.354492</td>\n      <td>1.799956</td>\n      <td>0.0</td>\n      <td>0.117215</td>\n      <td>0.000000</td>\n      <td>0.843189</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>M54200</td>\n      <td>0.104958</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.187106</td>\n      <td>1.199856</td>\n      <td>0.285849</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.319139</td>\n      <td>0.535698</td>\n      <td>1.611846</td>\n      <td>0.000000</td>\n      <td>1.367887</td>\n      <td>3.186100</td>\n      <td>0.0</td>\n      <td>2.389843</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>M42020</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.280975</td>\n      <td>0.000000</td>\n      <td>0.862255</td>\n      <td>0.000000</td>\n      <td>0.266741</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.040243</td>\n      <td>0.000000</td>\n      <td>0.794889</td>\n      <td>0.000000</td>\n      <td>1.341829</td>\n      <td>2.483617</td>\n      <td>0.0</td>\n      <td>1.689135</td>\n      <td>0.000000</td>\n      <td>0.022693</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>B53764</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.454560</td>\n      <td>1.099458</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.216294</td>\n      <td>0.000000</td>\n      <td>0.003337</td>\n      <td>2.232541</td>\n      <td>0.0</td>\n      <td>0.268575</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>19 rows Ã— 257 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pot.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:51:39.981124Z","iopub.execute_input":"2024-03-02T05:51:39.981666Z","iopub.status.idle":"2024-03-02T05:51:40.001155Z","shell.execute_reply.started":"2024-03-02T05:51:39.981627Z","shell.execute_reply":"2024-03-02T05:51:39.999098Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       ID   Sex        Height    Weight                    Hair   Eyes   Race  \\\n0  A00147  Male  5 ft. 07 in.  185 lbs.                   Brown   Blue  White   \n1  A00198  Male  6 ft. 02 in.  190 lbs.           Red or Auburn  Brown  White   \n2  A00360  Male  5 ft. 09 in.  167 lbs.  Gray or Partially Gray  Green  White   \n3  A00367  Male  6 ft. 00 in.  245 lbs.                   Black  Brown  Black   \n4  A01054  Male  5 ft. 07 in.  166 lbs.         Salt and Pepper  Brown  Black   \n\n   Sex Offender                                            Offense  \n0          True  AGGR KIDNAPPING-NO RANSOM, ATTEMPT MURDER/INTE...  \n1         False  CRIM DMG TO PROP $300-10K, ATTEMPT AGG BATTERY...  \n2         False  ARMED ROBBERY, OBSTRUCTING JUSTICE, CARRY/POSS...  \n3         False  THEFT CONTROL INTENT 10K, RET THEFT/DISP MERCH...  \n4          True  AGG CRIM SEX ASSAULT/WEAPON, ARMED ROBBERY, AG...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Sex</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>Hair</th>\n      <th>Eyes</th>\n      <th>Race</th>\n      <th>Sex Offender</th>\n      <th>Offense</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A00147</td>\n      <td>Male</td>\n      <td>5 ft. 07 in.</td>\n      <td>185 lbs.</td>\n      <td>Brown</td>\n      <td>Blue</td>\n      <td>White</td>\n      <td>True</td>\n      <td>AGGR KIDNAPPING-NO RANSOM, ATTEMPT MURDER/INTE...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A00198</td>\n      <td>Male</td>\n      <td>6 ft. 02 in.</td>\n      <td>190 lbs.</td>\n      <td>Red or Auburn</td>\n      <td>Brown</td>\n      <td>White</td>\n      <td>False</td>\n      <td>CRIM DMG TO PROP $300-10K, ATTEMPT AGG BATTERY...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A00360</td>\n      <td>Male</td>\n      <td>5 ft. 09 in.</td>\n      <td>167 lbs.</td>\n      <td>Gray or Partially Gray</td>\n      <td>Green</td>\n      <td>White</td>\n      <td>False</td>\n      <td>ARMED ROBBERY, OBSTRUCTING JUSTICE, CARRY/POSS...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A00367</td>\n      <td>Male</td>\n      <td>6 ft. 00 in.</td>\n      <td>245 lbs.</td>\n      <td>Black</td>\n      <td>Brown</td>\n      <td>Black</td>\n      <td>False</td>\n      <td>THEFT CONTROL INTENT 10K, RET THEFT/DISP MERCH...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A01054</td>\n      <td>Male</td>\n      <td>5 ft. 07 in.</td>\n      <td>166 lbs.</td>\n      <td>Salt and Pepper</td>\n      <td>Brown</td>\n      <td>Black</td>\n      <td>True</td>\n      <td>AGG CRIM SEX ASSAULT/WEAPON, ARMED ROBBERY, AG...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to convert height from 'ft. and in.' to 'inches'\ndef height_to_inches(height):\n    # Split the string by space and remove the 'ft.' and 'in.' parts\n    parts = height.lower().replace('ft.', '').replace('in.', '').split()\n    feet = int(parts[0]) if parts[0].isdigit() else 0\n    inches = int(parts[1]) if parts[1].isdigit() else 0\n    return feet * 12 + inches\n\n# Function to convert weight to pounds\ndef weight_to_pounds(weight):\n    # Remove all characters except the numeric and the negative sign\n    weight_part = ''.join(filter(str.isdigit, weight.replace('lbs', '')))\n    return int(weight_part) if weight_part.isdigit() else 0","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:12:56.925946Z","iopub.execute_input":"2024-03-02T06:12:56.926515Z","iopub.status.idle":"2024-03-02T06:12:56.935025Z","shell.execute_reply.started":"2024-03-02T06:12:56.926465Z","shell.execute_reply":"2024-03-02T06:12:56.933981Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Convert 'Height' to total inches\npot['Height_in_inches'] = pot['Height'].apply(height_to_inches)\n\n# Convert 'Weight' to pounds\npot['Weight_in_pounds'] = pot['Weight'].apply(weight_to_pounds)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:12:59.742783Z","iopub.execute_input":"2024-03-02T06:12:59.744120Z","iopub.status.idle":"2024-03-02T06:13:00.055191Z","shell.execute_reply.started":"2024-03-02T06:12:59.744062Z","shell.execute_reply":"2024-03-02T06:13:00.053967Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Calculate BMI\npot['BMI'] = 703 * pot['Weight_in_pounds'] / pot['Height_in_inches']**2","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:13:02.430491Z","iopub.execute_input":"2024-03-02T06:13:02.431074Z","iopub.status.idle":"2024-03-02T06:13:02.441937Z","shell.execute_reply.started":"2024-03-02T06:13:02.431034Z","shell.execute_reply":"2024-03-02T06:13:02.440148Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Display the updated DataFrame with the BMI column\nprint(pot.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:13:05.154688Z","iopub.execute_input":"2024-03-02T06:13:05.155101Z","iopub.status.idle":"2024-03-02T06:13:05.167093Z","shell.execute_reply.started":"2024-03-02T06:13:05.155069Z","shell.execute_reply":"2024-03-02T06:13:05.165980Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"       ID   Sex        Height    Weight                    Hair   Eyes   Race  \\\n0  A00147  Male  5 ft. 07 in.  185 lbs.                   Brown   Blue  White   \n1  A00198  Male  6 ft. 02 in.  190 lbs.           Red or Auburn  Brown  White   \n2  A00360  Male  5 ft. 09 in.  167 lbs.  Gray or Partially Gray  Green  White   \n3  A00367  Male  6 ft. 00 in.  245 lbs.                   Black  Brown  Black   \n4  A01054  Male  5 ft. 07 in.  166 lbs.         Salt and Pepper  Brown  Black   \n\n   Sex Offender                                            Offense  \\\n0          True  AGGR KIDNAPPING-NO RANSOM, ATTEMPT MURDER/INTE...   \n1         False  CRIM DMG TO PROP $300-10K, ATTEMPT AGG BATTERY...   \n2         False  ARMED ROBBERY, OBSTRUCTING JUSTICE, CARRY/POSS...   \n3         False  THEFT CONTROL INTENT 10K, RET THEFT/DISP MERCH...   \n4          True  AGG CRIM SEX ASSAULT/WEAPON, ARMED ROBBERY, AG...   \n\n   Height_in_inches  Weight_in_pounds        BMI  \n0                67               185  28.971931  \n1                74               190  24.391892  \n2                69               167  24.658895  \n3                72               245  33.224344  \n4                67               166  25.996436  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Now you can drop the temporary columns if you want\npot.drop(['Offense', 'Hair', 'Eyes', 'Race', 'Sex Offender'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:17:09.574726Z","iopub.execute_input":"2024-03-02T06:17:09.575218Z","iopub.status.idle":"2024-03-02T06:17:09.591446Z","shell.execute_reply.started":"2024-03-02T06:17:09.575179Z","shell.execute_reply":"2024-03-02T06:17:09.589749Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Display the updated DataFrame with the BMI column\npot.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:18:20.875146Z","iopub.execute_input":"2024-03-02T06:18:20.875698Z","iopub.status.idle":"2024-03-02T06:18:20.892500Z","shell.execute_reply.started":"2024-03-02T06:18:20.875662Z","shell.execute_reply":"2024-03-02T06:18:20.891061Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"       ID   Sex        Height    Weight        BMI\n0  A00147  Male  5 ft. 07 in.  185 lbs.  28.971931\n1  A00198  Male  6 ft. 02 in.  190 lbs.  24.391892\n2  A00360  Male  5 ft. 09 in.  167 lbs.  24.658895\n3  A00367  Male  6 ft. 00 in.  245 lbs.  33.224344\n4  A01054  Male  5 ft. 07 in.  166 lbs.  25.996436","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Sex</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>BMI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A00147</td>\n      <td>Male</td>\n      <td>5 ft. 07 in.</td>\n      <td>185 lbs.</td>\n      <td>28.971931</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A00198</td>\n      <td>Male</td>\n      <td>6 ft. 02 in.</td>\n      <td>190 lbs.</td>\n      <td>24.391892</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A00360</td>\n      <td>Male</td>\n      <td>5 ft. 09 in.</td>\n      <td>167 lbs.</td>\n      <td>24.658895</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A00367</td>\n      <td>Male</td>\n      <td>6 ft. 00 in.</td>\n      <td>245 lbs.</td>\n      <td>33.224344</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A01054</td>\n      <td>Male</td>\n      <td>5 ft. 07 in.</td>\n      <td>166 lbs.</td>\n      <td>25.996436</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pot.drop(['Sex', 'Height', 'Weight'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:21:51.928143Z","iopub.execute_input":"2024-03-02T06:21:51.928642Z","iopub.status.idle":"2024-03-02T06:21:51.939679Z","shell.execute_reply.started":"2024-03-02T06:21:51.928608Z","shell.execute_reply":"2024-03-02T06:21:51.937786Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"pot.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:22:03.058532Z","iopub.execute_input":"2024-03-02T06:22:03.058996Z","iopub.status.idle":"2024-03-02T06:22:03.073444Z","shell.execute_reply.started":"2024-03-02T06:22:03.058957Z","shell.execute_reply":"2024-03-02T06:22:03.071828Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"       ID        BMI\n0  A00147  28.971931\n1  A00198  24.391892\n2  A00360  24.658895\n3  A00367  33.224344\n4  A01054  25.996436","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>BMI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A00147</td>\n      <td>28.971931</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A00198</td>\n      <td>24.391892</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A00360</td>\n      <td>24.658895</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A00367</td>\n      <td>33.224344</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A01054</td>\n      <td>25.996436</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pit.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:21:54.134973Z","iopub.execute_input":"2024-03-02T06:21:54.135753Z","iopub.status.idle":"2024-03-02T06:21:54.173944Z","shell.execute_reply.started":"2024-03-02T06:21:54.135712Z","shell.execute_reply":"2024-03-02T06:21:54.172428Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"    label         0    1    2         3    4         5    6         7    8  \\\n0  M11813  0.111665  0.0  0.0  0.087155  0.0  0.283555  0.0  0.000000  0.0   \n1  M53326  0.000000  0.0  0.0  0.267790  0.0  0.466448  0.0  0.183102  0.0   \n2  Y22950  1.067019  0.0  0.0  0.354018  0.0  0.774819  0.0  0.000000  0.0   \n3  S09796  0.000000  0.0  0.0  0.000000  0.0  1.491947  0.0  0.575940  0.0   \n4  Y29851  0.000000  0.0  0.0  0.000000  0.0  1.106095  0.0  0.676816  0.0   \n\n   ...       246  247       248       249       250       251  252       253  \\\n0  ...  0.000000  0.0  0.945229  0.000000  1.393281  2.282689  0.0  0.973255   \n1  ...  0.501978  0.0  2.252731  0.000000  1.852022  3.060644  0.0  0.076265   \n2  ...  0.000000  0.0  0.651599  0.000000  1.578468  1.465300  0.0  0.529442   \n3  ...  0.000000  0.0  0.378559  0.000000  1.444114  2.393884  0.0  1.355780   \n4  ...  0.608241  0.0  0.362727  0.580366  0.235768  1.732123  0.0  0.844815   \n\n   254       255  \n0  0.0  0.000000  \n1  0.0  0.000000  \n2  0.0  0.417858  \n3  0.0  0.000000  \n4  0.0  0.000000  \n\n[5 rows x 257 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>246</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n      <th>250</th>\n      <th>251</th>\n      <th>252</th>\n      <th>253</th>\n      <th>254</th>\n      <th>255</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M11813</td>\n      <td>0.111665</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.087155</td>\n      <td>0.0</td>\n      <td>0.283555</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.945229</td>\n      <td>0.000000</td>\n      <td>1.393281</td>\n      <td>2.282689</td>\n      <td>0.0</td>\n      <td>0.973255</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M53326</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.267790</td>\n      <td>0.0</td>\n      <td>0.466448</td>\n      <td>0.0</td>\n      <td>0.183102</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.501978</td>\n      <td>0.0</td>\n      <td>2.252731</td>\n      <td>0.000000</td>\n      <td>1.852022</td>\n      <td>3.060644</td>\n      <td>0.0</td>\n      <td>0.076265</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Y22950</td>\n      <td>1.067019</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.354018</td>\n      <td>0.0</td>\n      <td>0.774819</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.651599</td>\n      <td>0.000000</td>\n      <td>1.578468</td>\n      <td>1.465300</td>\n      <td>0.0</td>\n      <td>0.529442</td>\n      <td>0.0</td>\n      <td>0.417858</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>S09796</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.491947</td>\n      <td>0.0</td>\n      <td>0.575940</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.378559</td>\n      <td>0.000000</td>\n      <td>1.444114</td>\n      <td>2.393884</td>\n      <td>0.0</td>\n      <td>1.355780</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Y29851</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.106095</td>\n      <td>0.0</td>\n      <td>0.676816</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.608241</td>\n      <td>0.0</td>\n      <td>0.362727</td>\n      <td>0.580366</td>\n      <td>0.235768</td>\n      <td>1.732123</td>\n      <td>0.0</td>\n      <td>0.844815</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 257 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pot['ID'] = pot['ID'].astype(str)\npit['label'] = pit['label'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:28:07.176811Z","iopub.execute_input":"2024-03-02T06:28:07.177281Z","iopub.status.idle":"2024-03-02T06:28:07.191315Z","shell.execute_reply.started":"2024-03-02T06:28:07.177251Z","shell.execute_reply":"2024-03-02T06:28:07.189897Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"merged_df = pit.merge(pot, left_on='label', right_on='ID', how='left')\n# The resulting `merged_df` will have all columns from `pit` plus the 'BMI' column from `pot`\n# If the 'ID' column from `pot` is not needed, you can drop it\nmerged_df.drop('ID', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:28:31.958113Z","iopub.execute_input":"2024-03-02T06:28:31.958577Z","iopub.status.idle":"2024-03-02T06:28:32.206522Z","shell.execute_reply.started":"2024-03-02T06:28:31.958543Z","shell.execute_reply":"2024-03-02T06:28:32.205143Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"merged_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:28:40.557837Z","iopub.execute_input":"2024-03-02T06:28:40.558301Z","iopub.status.idle":"2024-03-02T06:28:40.594281Z","shell.execute_reply.started":"2024-03-02T06:28:40.558268Z","shell.execute_reply":"2024-03-02T06:28:40.592762Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"    label         0    1    2         3    4         5    6         7    8  \\\n0  M11813  0.111665  0.0  0.0  0.087155  0.0  0.283555  0.0  0.000000  0.0   \n1  M53326  0.000000  0.0  0.0  0.267790  0.0  0.466448  0.0  0.183102  0.0   \n2  Y22950  1.067019  0.0  0.0  0.354018  0.0  0.774819  0.0  0.000000  0.0   \n3  S09796  0.000000  0.0  0.0  0.000000  0.0  1.491947  0.0  0.575940  0.0   \n4  Y29851  0.000000  0.0  0.0  0.000000  0.0  1.106095  0.0  0.676816  0.0   \n\n   ...  247       248       249       250       251  252       253  254  \\\n0  ...  0.0  0.945229  0.000000  1.393281  2.282689  0.0  0.973255  0.0   \n1  ...  0.0  2.252731  0.000000  1.852022  3.060644  0.0  0.076265  0.0   \n2  ...  0.0  0.651599  0.000000  1.578468  1.465300  0.0  0.529442  0.0   \n3  ...  0.0  0.378559  0.000000  1.444114  2.393884  0.0  1.355780  0.0   \n4  ...  0.0  0.362727  0.580366  0.235768  1.732123  0.0  0.844815  0.0   \n\n        255        BMI  \n0  0.000000  27.435721  \n1  0.000000  27.152471  \n2  0.417858  29.531611  \n3  0.000000  27.259184  \n4  0.000000  26.578450  \n\n[5 rows x 258 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n      <th>250</th>\n      <th>251</th>\n      <th>252</th>\n      <th>253</th>\n      <th>254</th>\n      <th>255</th>\n      <th>BMI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M11813</td>\n      <td>0.111665</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.087155</td>\n      <td>0.0</td>\n      <td>0.283555</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.945229</td>\n      <td>0.000000</td>\n      <td>1.393281</td>\n      <td>2.282689</td>\n      <td>0.0</td>\n      <td>0.973255</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>27.435721</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M53326</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.267790</td>\n      <td>0.0</td>\n      <td>0.466448</td>\n      <td>0.0</td>\n      <td>0.183102</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.252731</td>\n      <td>0.000000</td>\n      <td>1.852022</td>\n      <td>3.060644</td>\n      <td>0.0</td>\n      <td>0.076265</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>27.152471</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Y22950</td>\n      <td>1.067019</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.354018</td>\n      <td>0.0</td>\n      <td>0.774819</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.651599</td>\n      <td>0.000000</td>\n      <td>1.578468</td>\n      <td>1.465300</td>\n      <td>0.0</td>\n      <td>0.529442</td>\n      <td>0.0</td>\n      <td>0.417858</td>\n      <td>29.531611</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>S09796</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.491947</td>\n      <td>0.0</td>\n      <td>0.575940</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.378559</td>\n      <td>0.000000</td>\n      <td>1.444114</td>\n      <td>2.393884</td>\n      <td>0.0</td>\n      <td>1.355780</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>27.259184</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Y29851</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.106095</td>\n      <td>0.0</td>\n      <td>0.676816</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.362727</td>\n      <td>0.580366</td>\n      <td>0.235768</td>\n      <td>1.732123</td>\n      <td>0.0</td>\n      <td>0.844815</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>26.578450</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 258 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"merged_df.to_csv('/kaggle/working/merged.csv', index=False)  # Replace with your desired file path","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:29:26.603657Z","iopub.execute_input":"2024-03-02T06:29:26.604054Z","iopub.status.idle":"2024-03-02T06:29:48.326974Z","shell.execute_reply.started":"2024-03-02T06:29:26.604024Z","shell.execute_reply":"2024-03-02T06:29:48.325612Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/embed-front/merged.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:37:00.826426Z","iopub.execute_input":"2024-03-02T06:37:00.826917Z","iopub.status.idle":"2024-03-02T06:37:05.957346Z","shell.execute_reply.started":"2024-03-02T06:37:00.826882Z","shell.execute_reply":"2024-03-02T06:37:05.955898Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T06:37:13.802616Z","iopub.execute_input":"2024-03-02T06:37:13.803059Z","iopub.status.idle":"2024-03-02T06:37:13.842611Z","shell.execute_reply.started":"2024-03-02T06:37:13.803027Z","shell.execute_reply":"2024-03-02T06:37:13.841380Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"    label         0    1    2         3    4         5    6         7    8  \\\n0  M11813  0.111665  0.0  0.0  0.087155  0.0  0.283555  0.0  0.000000  0.0   \n1  M53326  0.000000  0.0  0.0  0.267790  0.0  0.466448  0.0  0.183102  0.0   \n2  Y22950  1.067019  0.0  0.0  0.354018  0.0  0.774819  0.0  0.000000  0.0   \n3  S09796  0.000000  0.0  0.0  0.000000  0.0  1.491947  0.0  0.575940  0.0   \n4  Y29851  0.000000  0.0  0.0  0.000000  0.0  1.106095  0.0  0.676816  0.0   \n\n   ...  247       248       249       250       251  252       253  254  \\\n0  ...  0.0  0.945229  0.000000  1.393281  2.282689  0.0  0.973255  0.0   \n1  ...  0.0  2.252731  0.000000  1.852022  3.060644  0.0  0.076265  0.0   \n2  ...  0.0  0.651599  0.000000  1.578468  1.465300  0.0  0.529442  0.0   \n3  ...  0.0  0.378559  0.000000  1.444114  2.393884  0.0  1.355780  0.0   \n4  ...  0.0  0.362727  0.580366  0.235768  1.732123  0.0  0.844815  0.0   \n\n        255        BMI  \n0  0.000000  27.435721  \n1  0.000000  27.152471  \n2  0.417858  29.531611  \n3  0.000000  27.259184  \n4  0.000000  26.578450  \n\n[5 rows x 258 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n      <th>250</th>\n      <th>251</th>\n      <th>252</th>\n      <th>253</th>\n      <th>254</th>\n      <th>255</th>\n      <th>BMI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M11813</td>\n      <td>0.111665</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.087155</td>\n      <td>0.0</td>\n      <td>0.283555</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.945229</td>\n      <td>0.000000</td>\n      <td>1.393281</td>\n      <td>2.282689</td>\n      <td>0.0</td>\n      <td>0.973255</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>27.435721</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M53326</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.267790</td>\n      <td>0.0</td>\n      <td>0.466448</td>\n      <td>0.0</td>\n      <td>0.183102</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.252731</td>\n      <td>0.000000</td>\n      <td>1.852022</td>\n      <td>3.060644</td>\n      <td>0.0</td>\n      <td>0.076265</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>27.152471</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Y22950</td>\n      <td>1.067019</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.354018</td>\n      <td>0.0</td>\n      <td>0.774819</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.651599</td>\n      <td>0.000000</td>\n      <td>1.578468</td>\n      <td>1.465300</td>\n      <td>0.0</td>\n      <td>0.529442</td>\n      <td>0.0</td>\n      <td>0.417858</td>\n      <td>29.531611</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>S09796</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.491947</td>\n      <td>0.0</td>\n      <td>0.575940</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.378559</td>\n      <td>0.000000</td>\n      <td>1.444114</td>\n      <td>2.393884</td>\n      <td>0.0</td>\n      <td>1.355780</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>27.259184</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Y29851</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.106095</td>\n      <td>0.0</td>\n      <td>0.676816</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.362727</td>\n      <td>0.580366</td>\n      <td>0.235768</td>\n      <td>1.732123</td>\n      <td>0.0</td>\n      <td>0.844815</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>26.578450</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 258 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Training the dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:15:58.310337Z","iopub.execute_input":"2024-03-02T08:15:58.310698Z","iopub.status.idle":"2024-03-02T08:16:13.276560Z","shell.execute_reply.started":"2024-03-02T08:15:58.310665Z","shell.execute_reply":"2024-03-02T08:16:13.275187Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the data\ndata = pd.read_csv('/kaggle/input/embed-front/merged.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:16:36.523952Z","iopub.execute_input":"2024-03-02T08:16:36.524620Z","iopub.status.idle":"2024-03-02T08:16:39.558068Z","shell.execute_reply.started":"2024-03-02T08:16:36.524592Z","shell.execute_reply":"2024-03-02T08:16:39.556897Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Split the data into features and labels\nX = data.iloc[:, 1:-1]  # all columns from '0' to '255' (face embeddings)\ny = data['BMI']  # the 'BMI' column","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:16:39.560042Z","iopub.execute_input":"2024-03-02T08:16:39.560563Z","iopub.status.idle":"2024-03-02T08:16:39.616917Z","shell.execute_reply.started":"2024-03-02T08:16:39.560532Z","shell.execute_reply":"2024-03-02T08:16:39.615675Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(X.isnull().sum().sum())\nprint(y.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:16:47.492087Z","iopub.execute_input":"2024-03-02T08:16:47.492464Z","iopub.status.idle":"2024-03-02T08:16:47.520259Z","shell.execute_reply.started":"2024-03-02T08:16:47.492427Z","shell.execute_reply":"2024-03-02T08:16:47.519269Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"0\n340\n","output_type":"stream"}]},{"cell_type":"code","source":"# Option 1: Remove rows with NaN BMI\ndata_cleaned = data.dropna(subset=['BMI'])","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:16:58.137616Z","iopub.execute_input":"2024-03-02T08:16:58.137987Z","iopub.status.idle":"2024-03-02T08:16:58.207045Z","shell.execute_reply.started":"2024-03-02T08:16:58.137938Z","shell.execute_reply":"2024-03-02T08:16:58.206041Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(\"NaNs in BMI after:\", data_cleaned['BMI'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:17:01.323722Z","iopub.execute_input":"2024-03-02T08:17:01.324146Z","iopub.status.idle":"2024-03-02T08:17:01.331125Z","shell.execute_reply.started":"2024-03-02T08:17:01.324110Z","shell.execute_reply":"2024-03-02T08:17:01.330332Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"NaNs in BMI after: 0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split the data into features and labels after cleaning or imputation\nX = data_cleaned.iloc[:, 1:-1]  # all columns from '0' to '255' (face embeddings)\ny = data_cleaned['BMI']  # the 'BMI' column after cleaning or imputation","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:17:03.337808Z","iopub.execute_input":"2024-03-02T08:17:03.338152Z","iopub.status.idle":"2024-03-02T08:17:03.386883Z","shell.execute_reply.started":"2024-03-02T08:17:03.338127Z","shell.execute_reply":"2024-03-02T08:17:03.385706Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Normalize the feature data\nscaler = StandardScaler()\nX_normalized = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:17:06.387150Z","iopub.execute_input":"2024-03-02T08:17:06.387617Z","iopub.status.idle":"2024-03-02T08:17:06.588712Z","shell.execute_reply.started":"2024-03-02T08:17:06.387578Z","shell.execute_reply":"2024-03-02T08:17:06.587915Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:17:08.571686Z","iopub.execute_input":"2024-03-02T08:17:08.572129Z","iopub.status.idle":"2024-03-02T08:17:08.800598Z","shell.execute_reply.started":"2024-03-02T08:17:08.572092Z","shell.execute_reply":"2024-03-02T08:17:08.799380Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Simple Neural Network Model for trails","metadata":{}},{"cell_type":"code","source":"# Define a simple neural network model\nmodel_train = keras.Sequential([\n    layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)  # Single output node for regression\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:17:20.786958Z","iopub.execute_input":"2024-03-02T08:17:20.787329Z","iopub.status.idle":"2024-03-02T08:17:20.993381Z","shell.execute_reply.started":"2024-03-02T08:17:20.787303Z","shell.execute_reply":"2024-03-02T08:17:20.991559Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel_train.compile(optimizer='adam', loss='mean_squared_error')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:17:33.916012Z","iopub.execute_input":"2024-03-02T08:17:33.916356Z","iopub.status.idle":"2024-03-02T08:17:33.936011Z","shell.execute_reply.started":"2024-03-02T08:17:33.916330Z","shell.execute_reply":"2024-03-02T08:17:33.934963Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model_train.fit(X_train, y_train, epochs=50, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:17:36.910867Z","iopub.execute_input":"2024-03-02T08:17:36.911263Z","iopub.status.idle":"2024-03-02T08:22:04.494261Z","shell.execute_reply.started":"2024-03-02T08:17:36.911231Z","shell.execute_reply":"2024-03-02T08:22:04.492721Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 36.8960 - val_loss: 28.5618\nEpoch 2/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 26.3090 - val_loss: 28.7176\nEpoch 3/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 24.6261 - val_loss: 27.5185\nEpoch 4/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 23.5227 - val_loss: 27.3655\nEpoch 5/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 22.4787 - val_loss: 27.1333\nEpoch 6/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 21.7207 - val_loss: 27.1596\nEpoch 7/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 20.6516 - val_loss: 28.2002\nEpoch 8/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 19.9531 - val_loss: 27.8526\nEpoch 9/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 19.0719 - val_loss: 28.1497\nEpoch 10/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 17.9836 - val_loss: 28.0845\nEpoch 11/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 16.9557 - val_loss: 28.4612\nEpoch 12/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 15.9267 - val_loss: 29.6914\nEpoch 13/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 14.7903 - val_loss: 29.4131\nEpoch 14/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 13.7331 - val_loss: 30.3759\nEpoch 15/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 12.7256 - val_loss: 31.3378\nEpoch 16/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 11.7432 - val_loss: 31.6830\nEpoch 17/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 10.8975 - val_loss: 31.9393\nEpoch 18/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 10.1630 - val_loss: 32.6096\nEpoch 19/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 9.4464 - val_loss: 33.0237\nEpoch 20/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 8.7610 - val_loss: 33.6321\nEpoch 21/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 8.2370 - val_loss: 33.9404\nEpoch 22/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 7.7504 - val_loss: 33.7747\nEpoch 23/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 7.2830 - val_loss: 34.2481\nEpoch 24/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 6.8717 - val_loss: 34.0147\nEpoch 25/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 6.4495 - val_loss: 34.6058\nEpoch 26/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 6.1012 - val_loss: 34.8462\nEpoch 27/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 5.8135 - val_loss: 35.4856\nEpoch 28/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 5.5614 - val_loss: 34.9615\nEpoch 29/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 5.2451 - val_loss: 35.1035\nEpoch 30/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 4.9674 - val_loss: 36.0169\nEpoch 31/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 4.8422 - val_loss: 35.9231\nEpoch 32/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 4.6083 - val_loss: 35.3695\nEpoch 33/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 4.3097 - val_loss: 36.5277\nEpoch 34/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 4.2350 - val_loss: 35.6445\nEpoch 35/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 4.0628 - val_loss: 35.6794\nEpoch 36/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 3.8575 - val_loss: 37.2414\nEpoch 37/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 3.7696 - val_loss: 36.3816\nEpoch 38/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 3.6513 - val_loss: 36.2983\nEpoch 39/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 3.5165 - val_loss: 36.7162\nEpoch 40/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 3.3158 - val_loss: 37.8878\nEpoch 41/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 3.5425 - val_loss: 36.6898\nEpoch 42/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 3.0980 - val_loss: 36.3216\nEpoch 43/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 3.0575 - val_loss: 36.1495\nEpoch 44/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 3.0081 - val_loss: 37.8077\nEpoch 45/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 2.8569 - val_loss: 37.5544\nEpoch 46/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 2.7300 - val_loss: 37.1704\nEpoch 47/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 2.6538 - val_loss: 37.2367\nEpoch 48/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 2.6409 - val_loss: 37.3654\nEpoch 49/50\n1384/1384 [==============================] - 6s 4ms/step - loss: 2.5241 - val_loss: 36.8714\nEpoch 50/50\n1384/1384 [==============================] - 5s 4ms/step - loss: 2.4933 - val_loss: 37.5369\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Loss is decreasing but val_loss is increasing, it indiacates, overfitting. ","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the test data\nloss = model_train.evaluate(X_test, y_test)\nprint(f'Test Loss: {loss}')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:22:06.890630Z","iopub.execute_input":"2024-03-02T08:22:06.891097Z","iopub.status.idle":"2024-03-02T08:22:08.254673Z","shell.execute_reply.started":"2024-03-02T08:22:06.891059Z","shell.execute_reply":"2024-03-02T08:22:08.252570Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"433/433 [==============================] - 1s 2ms/step - loss: 37.9350\nTest Loss: 37.93495178222656\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predictions\ny_pred = model_train.predict(X_test)\n\n# Calculate accuracy or other regression metrics\n# For regression, accuracy is not a meaningful metric. Instead, use RMSE, MSE, or MAE.\nmse = keras.metrics.mean_squared_error(y_test, y_pred)\nrmse = keras.backend.sqrt(mse)\nmae = keras.metrics.mean_absolute_error(y_test, y_pred)\n\nprint(f'Test MSE: {mse.numpy()}')\nprint(f'Test RMSE: {rmse.numpy()}')\nprint(f'Test MAE: {mae.numpy()}')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:22:12.026346Z","iopub.execute_input":"2024-03-02T08:22:12.026764Z","iopub.status.idle":"2024-03-02T08:22:13.828673Z","shell.execute_reply.started":"2024-03-02T08:22:12.026727Z","shell.execute_reply":"2024-03-02T08:22:13.827646Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"433/433 [==============================] - 1s 2ms/step\nTest MSE: [ 26.817083  90.09427   40.43979  ...  37.289013  41.3717   125.17625 ]\nTest RMSE: [ 5.178521   9.4918     6.3592286 ...  6.106473   6.4320836 11.188219 ]\nTest MAE: [ 3.984181   8.00723    4.673185  ...  5.1163516  5.449193  10.282669 ]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Ensure y_pred is flattened (since your model's output might have extra dimensions)\ny_pred_flattened = y_pred.flatten()\n\n# Calculate Pearson correlation coefficient\ncorrelation_matrix = np.corrcoef(y_test, y_pred_flattened)\npearson_correlation = correlation_matrix[0, 1]\n\nprint(f'Pearson Correlation Coefficient: {pearson_correlation}')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:24:24.681362Z","iopub.execute_input":"2024-03-02T08:24:24.681736Z","iopub.status.idle":"2024-03-02T08:24:24.691556Z","shell.execute_reply.started":"2024-03-02T08:24:24.681708Z","shell.execute_reply":"2024-03-02T08:24:24.690436Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Pearson Correlation Coefficient: 0.20170629538044893\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-03-02T07:26:03.120566Z","iopub.execute_input":"2024-03-02T07:26:03.121162Z","iopub.status.idle":"2024-03-02T07:26:03.246626Z","shell.execute_reply.started":"2024-03-02T07:26:03.121122Z","shell.execute_reply":"2024-03-02T07:26:03.245043Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# Initialize the linear regression model\nlr_model = LinearRegression()\n\n# Fit the model on the training data\nlr_model.fit(X_train, y_train)\n\n# Predict on the test data\ny_pred_lr = lr_model.predict(X_test)\n\n# Calculate the MSE, RMSE, and MAE\nmse_lr = mean_squared_error(y_test, y_pred_lr)\nrmse_lr = np.sqrt(mse_lr)\nmae_lr = mean_absolute_error(y_test, y_pred_lr)\n\nprint(f'Linear Regression Test MSE: {mse_lr}')\nprint(f'Linear Regression Test RMSE: {rmse_lr}')\nprint(f'Linear Regression Test MAE: {mae_lr}')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T07:26:26.399652Z","iopub.execute_input":"2024-03-02T07:26:26.400146Z","iopub.status.idle":"2024-03-02T07:26:28.534447Z","shell.execute_reply.started":"2024-03-02T07:26:26.400110Z","shell.execute_reply":"2024-03-02T07:26:28.526531Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Linear Regression Test MSE: 24.295604365655585\nLinear Regression Test RMSE: 4.9290571477368355\nLinear Regression Test MAE: 3.7660950877512005\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.stats import pearsonr","metadata":{"execution":{"iopub.status.busy":"2024-03-02T07:33:03.583216Z","iopub.execute_input":"2024-03-02T07:33:03.583730Z","iopub.status.idle":"2024-03-02T07:33:03.590047Z","shell.execute_reply.started":"2024-03-02T07:33:03.583698Z","shell.execute_reply":"2024-03-02T07:33:03.588932Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"correlation, _ = pearsonr(y_test, y_pred_lr)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T07:33:39.692312Z","iopub.execute_input":"2024-03-02T07:33:39.692798Z","iopub.status.idle":"2024-03-02T07:33:39.709839Z","shell.execute_reply.started":"2024-03-02T07:33:39.692763Z","shell.execute_reply":"2024-03-02T07:33:39.707968Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"print(f'Pearson Correlation Coefficient: {correlation}')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T07:33:50.505675Z","iopub.execute_input":"2024-03-02T07:33:50.506112Z","iopub.status.idle":"2024-03-02T07:33:50.513895Z","shell.execute_reply.started":"2024-03-02T07:33:50.506079Z","shell.execute_reply":"2024-03-02T07:33:50.512362Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Pearson Correlation Coefficient: 0.3073585559253895\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Random Forest Regressor for Regression\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# Initialize and train the Random Forest model\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:47:03.055700Z","iopub.execute_input":"2024-03-02T08:47:03.056171Z","iopub.status.idle":"2024-03-02T08:47:03.062911Z","shell.execute_reply.started":"2024-03-02T08:47:03.056132Z","shell.execute_reply":"2024-03-02T08:47:03.061040Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"rf_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T08:47:07.198203Z","iopub.execute_input":"2024-03-02T08:47:07.198585Z","iopub.status.idle":"2024-03-02T09:04:51.602997Z","shell.execute_reply.started":"2024-03-02T08:47:07.198550Z","shell.execute_reply":"2024-03-02T09:04:51.602011Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor(random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# Predict on the test set\ny_pred_rf = rf_model.predict(X_test)\n\n# Evaluate the model\nmse_rf = mean_squared_error(y_test, y_pred_rf)\nmae_rf = mean_absolute_error(y_test, y_pred_rf)\nprint(f'Random Forest Test MSE: {mse_rf}')\nprint(f'Random Forest Test MAE: {mae_rf}')\n\n# Calculate the Pearson correlation coefficient for the Random Forest model\npearson_corr_rf, _ = pearsonr(y_test, y_pred_rf)\nprint(f'Random Forest Pearson Correlation Coefficient: {pearson_corr_rf}')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T09:30:16.849197Z","iopub.execute_input":"2024-03-02T09:30:16.849576Z","iopub.status.idle":"2024-03-02T09:30:17.401503Z","shell.execute_reply.started":"2024-03-02T09:30:16.849545Z","shell.execute_reply":"2024-03-02T09:30:17.400401Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Random Forest Test MSE: 24.786031962346957\nRandom Forest Test MAE: 3.829730074226885\nRandom Forest Pearson Correlation Coefficient: 0.2789699908036613\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#  Using Vision Transformers\n\n![](https://www.mdpi.com/diagnostics/diagnostics-13-02459/article_deploy/html/images/diagnostics-13-02459-g001.png)\n\n","metadata":{}},{"cell_type":"code","source":"pip install torch torchvision transformers pandas","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:40:47.831015Z","iopub.execute_input":"2024-03-04T15:40:47.831981Z","iopub.status.idle":"2024-03-04T15:41:00.722212Z","shell.execute_reply.started":"2024-03-04T15:40:47.831944Z","shell.execute_reply":"2024-03-04T15:41:00.721008Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.24.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom torchvision.io import read_image\nfrom torchvision.transforms import Compose, Resize, Normalize, ToTensor\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:00.724293Z","iopub.execute_input":"2024-03-04T15:41:00.724983Z","iopub.status.idle":"2024-03-04T15:41:04.668925Z","shell.execute_reply.started":"2024-03-04T15:41:00.724945Z","shell.execute_reply":"2024-03-04T15:41:04.667772Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load BMI values\ndata_path = \"/kaggle/input/embed-front/merged.csv\"\nbmi_data = pd.read_csv(data_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:04.670379Z","iopub.execute_input":"2024-03-04T15:41:04.671792Z","iopub.status.idle":"2024-03-04T15:41:10.562240Z","shell.execute_reply.started":"2024-03-04T15:41:04.671754Z","shell.execute_reply":"2024-03-04T15:41:10.561163Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Check for 'nan' or 'inf' values in BMI and drop those rows\nif not bmi_data['BMI'].apply(np.isfinite).all():\n    print(\"BMI data contains nan or inf. Dropping those rows.\")\n    bmi_data = bmi_data.dropna(subset=['BMI'])\n    bmi_data = bmi_data[np.isfinite(bmi_data['BMI'])]","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:10.564732Z","iopub.execute_input":"2024-03-04T15:41:10.565041Z","iopub.status.idle":"2024-03-04T15:41:10.687318Z","shell.execute_reply.started":"2024-03-04T15:41:10.565016Z","shell.execute_reply":"2024-03-04T15:41:10.686206Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"BMI data contains nan or inf. Dropping those rows.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check for any 'nan' or 'inf' values in BMI and drop those rows\nif not np.isfinite(bmi_data['BMI']).all():\n    print(\"Data contains nan or inf. Dropping those rows.\")\n    bmi_data = bmi_data[np.isfinite(bmi_data['BMI'])]","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:10.688417Z","iopub.execute_input":"2024-03-04T15:41:10.688686Z","iopub.status.idle":"2024-03-04T15:41:10.694122Z","shell.execute_reply.started":"2024-03-04T15:41:10.688664Z","shell.execute_reply":"2024-03-04T15:41:10.693137Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torchvision.transforms import Compose, Resize, Normalize\nfrom torch.utils.data import Dataset, DataLoader\n\n# Define transformations\ntransform = Compose([\n    Resize((224, 224), antialias=True),\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:10.695453Z","iopub.execute_input":"2024-03-04T15:41:10.695795Z","iopub.status.idle":"2024-03-04T15:41:10.703662Z","shell.execute_reply.started":"2024-03-04T15:41:10.695757Z","shell.execute_reply":"2024-03-04T15:41:10.702876Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torchvision.transforms.functional import convert_image_dtype","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:10.704760Z","iopub.execute_input":"2024-03-04T15:41:10.705380Z","iopub.status.idle":"2024-03-04T15:41:10.712757Z","shell.execute_reply.started":"2024-03-04T15:41:10.705347Z","shell.execute_reply":"2024-03-04T15:41:10.711976Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class BMIDataset(Dataset):\n    def __init__(self, img_dir, bmi_data, transform=None):\n        self.img_dir = img_dir\n        # Assuming the 'ID' column in bmi_data DataFrame contains the image labels without the .jpg extension\n        self.bmi_data = bmi_data.set_index('label')  # Setting 'label' as index for easier lookup\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.bmi_data)\n\n    def __getitem__(self, idx):\n        img_label = self.bmi_data.index[idx]\n        img_path = f\"{self.img_dir}/{img_label}.jpg\"\n        image = read_image(img_path)  # This returns a tensor in torch.uint8\n        image = convert_image_dtype(image, dtype=torch.float)  # Convert to float\n        bmi = self.bmi_data.iloc[idx]['BMI']\n        if self.transform:\n            image = self.transform(image)\n        return image, bmi","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:10.713691Z","iopub.execute_input":"2024-03-04T15:41:10.713950Z","iopub.status.idle":"2024-03-04T15:41:10.722603Z","shell.execute_reply.started":"2024-03-04T15:41:10.713928Z","shell.execute_reply":"2024-03-04T15:41:10.721867Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Create the dataset and dataloader\nimg_dir = \"/kaggle/input/frontcrop/frontcropped\"","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:10.723617Z","iopub.execute_input":"2024-03-04T15:41:10.723879Z","iopub.status.idle":"2024-03-04T15:41:10.735122Z","shell.execute_reply.started":"2024-03-04T15:41:10.723856Z","shell.execute_reply":"2024-03-04T15:41:10.734324Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming bmi_data is your DataFrame\ntrain_data, test_data = train_test_split(bmi_data, test_size=0.2, random_state=42)  # 80% training, 20% testing\n\n# Optionally split train_data further to create a validation set\ntrain_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # Results in 60% train, 20% validation, 20% test","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:10.738851Z","iopub.execute_input":"2024-03-04T15:41:10.739188Z","iopub.status.idle":"2024-03-04T15:41:11.423525Z","shell.execute_reply.started":"2024-03-04T15:41:10.739163Z","shell.execute_reply":"2024-03-04T15:41:11.422467Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = BMIDataset(img_dir, train_data, transform=transform)\nval_dataset = BMIDataset(img_dir, val_data, transform=transform)  # If using a validation set\ntest_dataset = BMIDataset(img_dir, test_data, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # If using a validation set\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:41:11.424772Z","iopub.execute_input":"2024-03-04T15:41:11.425138Z","iopub.status.idle":"2024-03-04T15:41:11.486547Z","shell.execute_reply.started":"2024-03-04T15:41:11.425100Z","shell.execute_reply":"2024-03-04T15:41:11.485754Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:44:56.788999Z","iopub.execute_input":"2024-03-04T15:44:56.789849Z","iopub.status.idle":"2024-03-04T15:44:56.793749Z","shell.execute_reply.started":"2024-03-04T15:44:56.789812Z","shell.execute_reply":"2024-03-04T15:44:56.792809Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Check images for anomalies\nfor i, (imgs, bmis) in enumerate(train_loader):\n    if not torch.isfinite(imgs).all():\n        print(f\"Images at batch index {i} contain nan or inf.\")\n    if not np.isfinite(bmis.numpy()).all():  # Convert entire tensor to numpy and then check with np.isfinite\n        print(f\"BMI values at batch index {i} contain nan or inf.\")\n        \n# Check images for anomalies\nfor i, (imgs, bmis) in enumerate(val_loader):\n    if not torch.isfinite(imgs).all():\n        print(f\"Images at batch index {i} contain nan or inf.\")\n    if not np.isfinite(bmis.numpy()).all():  # Convert entire tensor to numpy and then check with np.isfinite\n        print(f\"BMI values at batch index {i} contain nan or inf.\")\n        \n\n# Check images for anomalies\nfor i, (imgs, bmis) in enumerate(test_loader):\n    if not torch.isfinite(imgs).all():\n        print(f\"Images at batch index {i} contain nan or inf.\")\n    if not np.isfinite(bmis.numpy()).all():  # Convert entire tensor to numpy and then check with np.isfinite\n        print(f\"BMI values at batch index {i} contain nan or inf.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:45:00.537094Z","iopub.execute_input":"2024-03-04T15:45:00.537687Z","iopub.status.idle":"2024-03-04T15:58:07.267388Z","shell.execute_reply.started":"2024-03-04T15:45:00.537655Z","shell.execute_reply":"2024-03-04T15:58:07.266248Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-03-04T15:58:07.269508Z","iopub.execute_input":"2024-03-04T15:58:07.270140Z","iopub.status.idle":"2024-03-04T15:58:07.274767Z","shell.execute_reply.started":"2024-03-04T15:58:07.270077Z","shell.execute_reply":"2024-03-04T15:58:07.273814Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Correct usage of DataLoader in a for loop\nfor i, (img, bmi) in enumerate(train_loader):\n    if not torch.isfinite(img).all():\n        print(f\"Image at index {i} contains nan or inf.\")\n    if not np.isfinite(bmi.numpy()).all():  # Use .all() for batched data\n        print(f\"BMI value at batch index {i} is nan or inf.\")\n        \nfor i, (img, bmi) in enumerate(val_loader):\n    if not torch.isfinite(img).all():\n        print(f\"Image at index {i} contains nan or inf.\")\n    if not np.isfinite(bmi.numpy()).all():  # Use .all() for batched data\n        print(f\"BMI value at batch index {i} is nan or inf.\")\n\nfor i, (img, bmi) in enumerate(test_loader):\n    if not torch.isfinite(img).all():\n        print(f\"Image at index {i} contains nan or inf.\")\n    if not np.isfinite(bmi.numpy()).all():  # Use .all() for batched data\n        print(f\"BMI value at batch index {i} is nan or inf.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:15:07.696155Z","iopub.execute_input":"2024-03-04T16:15:07.697071Z","iopub.status.idle":"2024-03-04T16:21:07.609023Z","shell.execute_reply.started":"2024-03-04T16:15:07.697036Z","shell.execute_reply":"2024-03-04T16:21:07.607894Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Check images for anomalies\nfor i in range(len(train_dataset)):\n    img, bmi = train_dataset[i]\n    if not torch.isfinite(img).all():\n        print(f\"Image at index {i} contains nan or inf.\")\n    # Assuming bmi is a scalar float or numpy.float64 at this point, not a tensor\n    if not np.isfinite(bmi):  # Correct use of np.isfinite for scalar values\n        print(f\"BMI value at index {i} is nan or inf.\")\n        \n# Check images for anomalies\nfor i in range(len(val_dataset)):\n    img, bmi = val_dataset[i]\n    if not torch.isfinite(img).all():\n        print(f\"Image at index {i} contains nan or inf.\")\n    # Assuming bmi is a scalar float or numpy.float64 at this point, not a tensor\n    if not np.isfinite(bmi):  # Correct use of np.isfinite for scalar values\n        print(f\"BMI value at index {i} is nan or inf.\")\n\n# Check images for anomalies\nfor i in range(len(test_dataset)):\n    img, bmi = test_dataset[i]\n    if not torch.isfinite(img).all():\n        print(f\"Image at index {i} contains nan or inf.\")\n    # Assuming bmi is a scalar float or numpy.float64 at this point, not a tensor\n    if not np.isfinite(bmi):  # Correct use of np.isfinite for scalar values\n        print(f\"BMI value at index {i} is nan or inf.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:24:02.889339Z","iopub.execute_input":"2024-03-04T16:24:02.890116Z","iopub.status.idle":"2024-03-04T16:27:45.728553Z","shell.execute_reply.started":"2024-03-04T16:24:02.890072Z","shell.execute_reply":"2024-03-04T16:27:45.727533Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import ViTFeatureExtractor, ViTForImageClassification\nfrom torch import nn","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:27:45.730233Z","iopub.execute_input":"2024-03-04T16:27:45.730565Z","iopub.status.idle":"2024-03-04T16:27:57.708204Z","shell.execute_reply.started":"2024-03-04T16:27:45.730539Z","shell.execute_reply":"2024-03-04T16:27:57.707227Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained ViT model\nmodel_name = \"google/vit-base-patch16-224-in21k\"\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\nmodel = ViTForImageClassification.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:27:57.709527Z","iopub.execute_input":"2024-03-04T16:27:57.710181Z","iopub.status.idle":"2024-03-04T16:27:59.591372Z","shell.execute_reply.started":"2024-03-04T16:27:57.710148Z","shell.execute_reply":"2024-03-04T16:27:59.590420Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41e5b38669e44773a1aa07b6aa8d800d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d8f956c0be84c97960f14771b79551c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec23d5a60044e30994efc7b57fa4b5b"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Modify the model for regression\nmodel.classifier = nn.Linear(model.config.hidden_size, 1) # Assuming the output is a single continuous value for BMI","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:27:59.593842Z","iopub.execute_input":"2024-03-04T16:27:59.594555Z","iopub.status.idle":"2024-03-04T16:27:59.599182Z","shell.execute_reply.started":"2024-03-04T16:27:59.594516Z","shell.execute_reply":"2024-03-04T16:27:59.598238Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.optim import Adam\nfrom torch.nn import MSELoss\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\noptimizer = Adam(model.parameters(), lr=1e-5)\nloss_fn = MSELoss()\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    for images, bmis in train_loader:\n        images = images.to(device)\n        bmis = bmis.to(device).float().unsqueeze(1)  # Ensure BMI is the correct shape\n\n        optimizer.zero_grad()\n        outputs = model(images).logits\n        loss = loss_fn(outputs, bmis)\n        loss.backward()\n        optimizer.step()\n        \n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        val_loss = 0\n        for images, bmis in val_loader:\n            images = images.to(device)\n            bmis = bmis.to(device).float().unsqueeze(1)\n            outputs = model(images).logits\n            loss = loss_fn(outputs, bmis)\n            # Your validation process here\n            val_loss += loss.item()\n        val_loss /= len(val_loader)\n    print(f\"Epoch {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:27:59.600381Z","iopub.execute_input":"2024-03-04T16:27:59.600666Z","iopub.status.idle":"2024-03-04T19:01:11.352418Z","shell.execute_reply.started":"2024-03-04T16:27:59.600632Z","shell.execute_reply":"2024-03-04T19:01:11.351417Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1, Training Loss: 445.8351135253906, Validation Loss: 511.3405130223369\nEpoch 2, Training Loss: 318.3039245605469, Validation Loss: 374.5161909495435\nEpoch 3, Training Loss: 202.1973114013672, Validation Loss: 247.99044704657504\nEpoch 4, Training Loss: 111.11869049072266, Validation Loss: 145.98374954822708\nEpoch 5, Training Loss: 51.985435485839844, Validation Loss: 76.04647754026065\nEpoch 6, Training Loss: 25.26141357421875, Validation Loss: 39.74374608795307\nEpoch 7, Training Loss: 20.916349411010742, Validation Loss: 28.744338101657927\nEpoch 8, Training Loss: 22.36387062072754, Validation Loss: 27.615343087264627\nEpoch 9, Training Loss: 20.633249282836914, Validation Loss: 26.892218466443772\nEpoch 10, Training Loss: 18.58112335205078, Validation Loss: 22.522558715547206\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\ntest_loss = 0\n\nwith torch.no_grad():\n    for images, bmis in test_loader:\n        images = images.to(device)  # Move images to the same device as the model\n        bmis = bmis.to(device).float().unsqueeze(1)  # Ensure BMIs are on the same device and match expected shape\n\n        outputs = model(images).logits  # Assuming your model returns logits directly\n        loss = loss_fn(outputs, bmis)\n        test_loss += loss.item()\n\ntest_loss /= len(test_loader)\nprint(f\"Test Loss: {test_loss}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:03:19.825683Z","iopub.execute_input":"2024-03-04T19:03:19.826607Z","iopub.status.idle":"2024-03-04T19:05:34.356885Z","shell.execute_reply.started":"2024-03-04T19:03:19.826572Z","shell.execute_reply":"2024-03-04T19:05:34.355930Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Test Loss: 21.97793846372644\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Accuracy","metadata":{}},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\npredictions = []  # Initialize an empty list to store predictions\nactuals = []  # Initialize an empty list to store actual BMI values\n\nwith torch.no_grad():\n    for images, bmis in test_loader:\n        images = images.to(device)\n        bmis = bmis.to(device).float().unsqueeze(1)\n        \n        # Get model predictions\n        output = model(images).logits.squeeze(1)  # Adjust depending on your model's output shape\n        predictions.extend(output.cpu().numpy())  # Append predictions to the list\n        actuals.extend(bmis.cpu().numpy().squeeze(1))  # Append actual BMI values to the list\n\n# Now you have populated 'predictions' and 'actuals', you can convert them to numpy arrays\npredictions = np.array(predictions)\nactuals = np.array(actuals)\n\n# Then calculate the metrics\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nmae = mean_absolute_error(actuals, predictions)\nmse = mean_squared_error(actuals, predictions)\nrmse = np.sqrt(mse)\nr2 = r2_score(actuals, predictions)\n\nprint(f\"Mean Absolute Error (MAE): {mae:.4f}\")\nprint(f\"Mean Squared Error (MSE): {mse:.4f}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\nprint(f\"R-squared (RÂ²): {r2:.4f}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:08:45.732116Z","iopub.execute_input":"2024-03-04T19:08:45.732842Z","iopub.status.idle":"2024-03-04T19:10:47.063890Z","shell.execute_reply.started":"2024-03-04T19:08:45.732810Z","shell.execute_reply":"2024-03-04T19:10:47.062933Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Mean Absolute Error (MAE): 3.4764\nMean Squared Error (MSE): 21.9643\nRoot Mean Squared Error (RMSE): 4.6866\nR-squared (RÂ²): 0.1807\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.stats import pearsonr","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:12:39.088562Z","iopub.execute_input":"2024-03-04T19:12:39.089566Z","iopub.status.idle":"2024-03-04T19:12:39.093623Z","shell.execute_reply.started":"2024-03-04T19:12:39.089525Z","shell.execute_reply":"2024-03-04T19:12:39.092762Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Calculate Pearson correlation coefficient\npearson_corr, _ = pearsonr(actuals, predictions)\nprint(f\"Pearson Correlation Coefficient: {pearson_corr:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:13:00.976706Z","iopub.execute_input":"2024-03-04T19:13:00.977541Z","iopub.status.idle":"2024-03-04T19:13:01.001417Z","shell.execute_reply.started":"2024-03-04T19:13:00.977507Z","shell.execute_reply":"2024-03-04T19:13:01.000582Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Pearson Correlation Coefficient: 0.4525\n","output_type":"stream"}]}]}